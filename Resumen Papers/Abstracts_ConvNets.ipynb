{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad Galileo\n",
    "\n",
    "Statistical Learning 2\n",
    "\n",
    "PAPD - Sección V\n",
    "\n",
    "Sergio José Barrios Martínez\n",
    "\n",
    "Carnet No. 19012765\n",
    "\n",
    "# Proyecto Final Curso\n",
    "\n",
    "## Detalles Importantes de Papers de ConvNets\n",
    "\n",
    "En el presente Notebook se muestran los aspectos más relevantes de los Papers Relacionados a ConvNets que se vieron durante el curso. De forma específica:\n",
    "- BatchNorm\n",
    "- DenseNet\n",
    "- DropOut\n",
    "- ELMo\n",
    "- Faster-R-CNN\n",
    "- GRU\n",
    "- Inception\n",
    "- Object Recognition with Gradient-Based Learning\n",
    "- LSTM\n",
    "- Mask-R-CNN\n",
    "- MobileNet\n",
    "- ResNet\n",
    "- Retina-Net\n",
    "- Style Transfer\n",
    "- T-SNE\n",
    "- U-Net\n",
    "- VGG\n",
    "- Xavier Initialization\n",
    "- YOLO900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNorm\n",
    "\n",
    "*Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167.*\n",
    "\n",
    "Este paper trata sobre una solución a un problema que se da cuando se entrenan Redes Neuronales Profundas (que tienen varias capas ocultas). Esta arquitectura de las redes neuronales hace que los parámetros de una capa oculta específica cambian a medida que los parámetros de las capas ocultas anteriores cambian. Esto complica el entrenamiento pues requiere que la experimentación inice con Learning Rates muy bajos y es muy sensible a la inicialización de los parámetros.\n",
    "\n",
    "A este fenómeno se le denomina cambio covariado interno (*internal covariate shift*). El paper propone una forma de reducir esta covarianza utilizando una capa de \"normalización\" antes de la entrada a cada capa. Esta solución se implementa incluyendo a la normalización como parte de la arquitectura de la red (capa de normalización), y ejecutando esta normalización **con cada mini-batch de entrenamiento**, es decir, la normalización no ocurre solo una vez, sino que al ser parte del modelo, se ejecuta cada vez que exista propagación de entradas.\n",
    "\n",
    "El **batch-normalization** permite experimentar con Learning Rates más grandes y que el modelo sea menos sensible a la inicialización de parámetros de las capas. También dado que trabaja con cada propagación, actúa como un regularizador, similar a lo que hace Dropout para combatir el problema de overfitting a los que son propensos los modelos profundos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "*Huang, G., Liu, Z., Van Der Maaten, L., & Weinberger, K. Q. (2017). Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4700-4708).*\n",
    "\n",
    "El paper sostiene que existen estudios que muestran que las Redes Convolucionales Profundas funcionan mejor cuando existen conexiones cortas entre capas que están cercanas a la salida y cercanas a la entrada. Las Redes Neuronales Convolucionales tradicionalmente se conectan secuencialmente, una capa a la siguiente capa. Se introduce entonces la idea de conectar una capa con todas las demás capas, de forma Feed-Forward (arquitectura llamada **DenseNet**):\n",
    "- Para cada capa se utilizan como entradas TODOS los feature maps de las capas anteriores.\n",
    "- Para cada capa, su propio feature map es utilizado como entrada para las capas subsiguientes.\n",
    "Las ventajas que esto tiene, acorde al paper, es que reducen el problema del \"desvanecimiento del gradiente\", ayudan a la propagación de features, propician la re-utilización de features y reducen la cantidad de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "*Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), 1929-1958.*\n",
    "\n",
    "Este paper introduce el concepto de \"daño neuronal\" como técnica para combatir el overfitting a los que son propensos los modelos de aprendizaje profundo. Las redes neuronales profundas utilizan muchos parámetros, y aunque pueden llegar a ser muy precisas, también pueden ser muy lentas de utilizar. Las técnicas de combinación de predicciones de diferentes modelos (ensemble learning) es entonces algo difícil de realizar en este tipo de modelos para combatir el overfitting.\n",
    "La técnica de **Dropout** es de eliminar unidades y sus conexiones ***durante el entrenamiento***, para reducir el problema de co-adaptación. Durante el entrenamiento, Dropout muestrea sobre un número exponencial de redes \"debilitadas\" o con menos unidades (y conexiones) de forma que el efecto final durante el testing es aproximadamente igual al resultado de promediar el efecto de todas estas redes debilitadas en una sola red, que tiene pesos más pequeños.\n",
    "Esto **reduce significativamente el overfitting** y proporciona efectos superiores a otros métodos de regularización.\n",
    "\n",
    "**Nota: Se utilizó esta técnica de regularización utilizando Keras en la parte 1 del proyecto final, para reducir overfitting en este modelo profundo de clasificación binaria**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMo\n",
    "*Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). Deep contextualized word representations. arXiv preprint arXiv:1802.05365.*\n",
    "\n",
    "Este paper introduce un modelo de *embedding* de palabras que incluye \"contextualización profunda\", incluyendo características complejas de modelar en el uso de las palabras (sintáxis y semántica) y cómo se utilizan estas características en los distintos contextos lingüísticos. Este conjunto de vectores son funciones aprendidas de estados internos (representaciones intermedias) de un modelo bidireccional profundo de lenguaje (llamados también **biLM**), que es pre-entrenado en un corpus de texto extenso.\n",
    "Se muestra que estas representaciones pueden utilizarse a modelos existentes para mejorar su desempeño (transfer learning) y se muestra su aplicación en varias tareas de NLP (como resolución de preguntas y análisis de sentimientos.\n",
    "\n",
    "**Nota: Este paper se describe en detalle en la parte 2 del proyecto final, ya que se utilizaron \"embeddings\" de ELMo como entrada para un modelo biLM para análisis de sentimientos de reviews en tres sitios web.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster R-CNN\n",
    "*Ren, S., He, K., Girshick, R., & Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems (pp. 91-99).*\n",
    "\n",
    "Las redes neuronales para detección de objetos dependen de algoritmos que puedan trabajar en el dominio espacial para realizar hipótesis sobre la localización de los objetos. SPPnet y R-CNN son mostrados como soluciones para reducir el tiempo de ejecución de estas redes de detección, lo que evidenció que este proceso de cálculo de regiones propuestas es un \"cuello de botella\" en estos algoritmos.\n",
    "En el paper se introduce la idea de Red de Propuesta de Regiones (RPN) para compartir las features convolucionales completas con la red de detección, lo que produce propuestas de regiones \"libres de  costo\". RPN es una red convolucional que simultáneamente predice las fronteras del objeto y las puntuaciones del objeto (que tan bien el detector identifica las localizaciones y las clases de objetos).\n",
    "\n",
    "RPN se utiliza para generar propuestas de regiones, que son alimentadas a la red Fast R-CNN para detección. Posteriormente se fusionan RPN y Faster R-CNN en una sola red, compartiendo sus features convolucionales (con mecanismos de atención)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "*Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., & Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078.*\n",
    "\n",
    "Este paper introduce un modelo de Red Neruronal Recurrente (RNN) llamada RNN Encoder-Decoder. En esta arquitectura, una RNN codifica una secuencia de símbolos en una representación vectorial de tamaño fijo, y otra RNN decodifica esta representación a otra secuencia de símbolos. Estos modelos de codificación-decodificación se entrenan conjuntamente para maximizar la probabilidad condicional de una secuencia objetivo dada una secuencia fuente de entrada. Esto se muestra que ayuda a mejorar los sistemas de traducción de máquina utilizando la probabilidad condicional de parejas de frases. Cualitativamente, este modelo es capaz de aprender representaciones semánticas y sintácticas de frases lingüísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception\n",
    "*Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., ... & Rabinovich, A. (2015). Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1-9).*\n",
    "\n",
    "Se introduce la idea de una red neuronal convolucional profunda (llamada Inception) que tuvo éxito sobre el Challenge de 2014 de reconocimiento visual sobre el dataset ImageNet. La mejora sustancial introducida por este modelo es la eficiencia en el uso de los recursos computacionales dentro de la red. Esto se logra cuando se permite modificar la profundidad y el ancho de la red, manteniendo las restricciones de capacidad computacional constantes (basado en el principio Hebbian). Un ejemplo de esta red es GoogLeNet, utilizada para clasificación y detección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Recognition with Gradient Based Learning\n",
    "*LeCun, Y., Haffner, P., Bottou, L., & Bengio, Y. (1999). Object recognition with gradient-based learning. In Shape, contour and grouping in computer vision (pp. 319-345). Springer, Berlin, Heidelberg.*\n",
    "\n",
    "Este paper trata sobre cómo puede alimentarse un modelo de reconocimiento de formas con información mínimamente procesada y dejar que el modelo mismo encuentre el conjunto apropiado de representaciones a través de un aprendizaje basado en Gradientes, especialmente con Redes Neuronales Convolucionales. Se muestra como estas redes pueden utilizarse para reconocer múltiples objetos sin requerir una separación explícita de su entorno. Se introduce también el modelo conocido como **Graph Transformer Network** que extiende los conceptos de aprendizaje basado en gradientes a sistemas basados en Grafos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (Long Short-term Memory)\n",
    "*Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780.*\n",
    "\n",
    "Este paper trata de solucionar el problema que existe en la cantidad de tiempo requerida para almacenar información en períodos largos de tiempo en una red neuronal recurrente. Según el estudio, esto ocurre por el desvanecimiento del error que ocurre en la propagación inversa del error en este tipo de redes recurrentes. Para solucionar este problema, se introduce el métodología conocida como LSTM (Long Short-Term Memory). Este método puede aprender a reducir tiempos de entrenamiento. Se realiza con **\"compuertas multiplicativas\"** que aprenden a abrir o cerrar el acceso al flujo del error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask R-CNN\n",
    "*He, K., Gkioxari, G., Dollár, P., & Girshick, R. (2017). Mask r-cnn. In Proceedings of the IEEE international conference on computer vision (pp. 2961-2969).*\n",
    "\n",
    "Este trabajo presenta un marco de trabajo para **segmentación por instancias**. Es decir, no solo detecta objetos en la imagen, sino que además genera máscaras que identifican distintas instancias del mismo objeto. La metodología se denomina Mask R-CNN y es una extensión a Faster R-CNN en la cual se predice una máscara para el objeto, además de identificar el tipo de objeto. Se muestran resultados sobre el dataset COCO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet\n",
    "*Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., ... & Adam, H. (2017). Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861.*\n",
    "\n",
    "Este trabajo introduce una clase de **modelos más eficientes para utilizar en aplicaciones móbiles y aplicaciones de visión embebidas**. Esta basado en una arquitectura que permite obtener convoluciones separables por profundidad, que permite obtener modelos profundos más ligeros. Se introducen dos hiperparámetros que permiten ajustar el balance entre precisión y latencia de la red. Se presentan resultados sobre el dataset de ImageNet, y sobre distintas aplicaciones como detección de objetos, clasificación, detección de facciones y geo-localización de gran escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet\n",
    "*He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).*\n",
    "\n",
    "Se introduce un marco de trabajo para entrenamiento de redes neuronales profundas, para facilitar el mismo. Se basa en reformular cada capa como **funciones de aprendizaje residual** con referencia a las entradas de la capa, en lugar de aprender funciones sin referencia. Se muestra evidencia que este tipo de redes son más fáciles de optimizar y lograr mayor precisión al alcanzar mayores profundidades. Se presentan resultados sobre los datasets ImageNet y COCO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetinaNet\n",
    "*Lin, T. Y., Goyal, P., Girshick, R., He, K., & Dollár, P. (2017). Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision (pp. 2980-2988).*\n",
    "\n",
    "Este paper compara el desempeño de metodologías de dos etapas (como R-CNN) vrs. metodologías de una etapa y cómo ésta última no logra la precisión de las primeras. Se investigan las causas de esto, entre ellas un imbalance de clases encontrado durante el entrenamiento de estos detectores densos. La solución propuesta es una modificación a la función de costo de entropía cruzada que reduce la ponderación del costo de los ejemplos que han sido bien calificados (**Focal Loss**). Para probar esta función, se presenta un detector denso simple llamado **RetinaNet**, con el cual se logra la velocidad de los detectores de una etapa, y logra mayor precisión que los detectores de dos etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer\n",
    "#### A Neural Algorithm of Artistic Style (Paper Seleccionado para Proyecto Parte 2).\n",
    "*Gatys, L. A., Ecker, A. S., & Bethge, M. (2015). A neural algorithm of artistic style. arXiv preprint arXiv:1508.06576.*\n",
    "\n",
    "En este paper se introduce un sistema basado en redes neuronales convolucionales profundas que crea imágenes artísticas de gran calidad perceptual. Este sistema se basa en la combinación de representaciones neuronales para separar y recombinar contenido y estilo de imágenes arbitrarias.\n",
    "\n",
    "Básicamente se aprovecha de que las redes neuronales convolucionales al entrenarse para reconocer objetos, desarrollan representaciones jerárquicas. Es decir, cada imagen de entrada es transformada en representaciones que tienen que ver más con el **contenido de una imagen** que con el valor pixel a pixel. Entonces se puede visualizar el contenido actual de cada capa por medio de la reconstrucción de la imagen a partir de los feature maps de cierta capa. \n",
    "\n",
    "En general, capas más altas resumen contenido de alto nivel en términos de objetos y su distribución en la imagen. En comparación, capas más bajas (cercanas a la entrada) resumen contenido de bajo nivel que reproducen los valores exactos de los pixeles de la imagen.\n",
    "\n",
    "##### Obtención del Estilo de una Imagen:\n",
    "Se utiliza un espacio de features destinado a capturar información de la textura. Este espacio está construido encima de cada una de las respuestas de los filtros en cada capa de la red. Incluyendo las correlaciones de cada capa, puede obtenerse representación multi-escala de la imagen de entrada, que captura la textura pero no el arreglo global.\n",
    "\n",
    "El descubrimiento clave de este paper es que las representaciones de contenido y de estilo en una Red Neuronal Convolucional son separables. Esto es, se puede manipular ambas representaciones independientemente para producir nuevas imagenes con sentido perceptivo.\n",
    "\n",
    "Adicionalmente, puede observarse el contenido de cada filtro y verificar cómo se realiza esta captura de textura y contenido.\n",
    "\n",
    "#### Función de Costo\n",
    "En este caso, la función de costo tiene una forma particular: Mide el error cuadrático entre dos representaciones de características:\n",
    "\n",
    "<img src=\"./imagenes/costo.png\">\n",
    "\n",
    "Adicional, la derivada de este costo respecto a la capa *l*:\n",
    "\n",
    "<img src=\"./imagenes/derivadas.png\">\n",
    "\n",
    "En el paper se experimenta con el contenido de las capas convolucionales 1-1, 2-1, 3-1, 4-1 y 5-1 de la red VGG original.\n",
    "Sobre estas respuestas de la red, se construye una representación de estilo que *calcula la correlación* entre las diferentes respuestas de los filtros. Esto se calcula por medio de la **matriz Gram** que no es más que el producto punto entre el feature map vectorizado *i* y *j* de una capa *l* como medida de similitud:\n",
    "\n",
    "<img src=\"./imagenes/gram.png\">\n",
    "\n",
    "\n",
    "Entonces para general la textura de la imagen de estilo sobre la imagen de contenido se minimiza la distancia entre la matriz Gram de la imagen original y la matriz gram de la imagen a ser generada. Se propone entonces una función de **Costo Total**, ponderando la pérdida en **contenido** y la pérdida en **estilo**:\n",
    "\n",
    "<img src=\"./imagenes/costo_total.png\">\n",
    "\n",
    "\n",
    "Donde Alfa y Beta representan las ponderaciones de reconstrucción para el **contenido** y el **estilo** respectivamente.\n",
    "\n",
    "**Nota: Más detalles al respecto en la parte 2 del proyecto final, donde se experimenta con transferencia de estilo y visualización de representaciones intermedias.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "*Maaten, L. V. D., & Hinton, G. (2008). Visualizing data using t-SNE. Journal of machine learning research, 9(Nov), 2579-2605.*\n",
    "\n",
    "Este paper trata sobre uno de los **métodos de reducción de dimensionalidad** vistos en clase. Por medio de esta metodología pueden \"visualizarse\" datos de alta dimensionalidad, dando a cada observación un lugar en un mapa de dos o tres dimensiones. Es una variación de la metodología conocida como Stochastic Neighbor Embedding que es más fácil de optimizar y que produce mejores resultados al evitar la acumulación de puntos en el centro del mapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net\n",
    "*Ronneberger, O., Fischer, P., & Brox, T. (2015, October). U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention (pp. 234-241). Springer, Cham.*\n",
    "\n",
    "Este paper trata el problema que tienen las redes neuronales profundas de necesitar grandes cantidades de información para el entrenamiento. Se presenta una estrategia que se basa en el uso exhaustivo de **data augmentation** para utilizar de manera más eficiente los ejemplos de entrenamiento con los que se cuenta. Esta arquitectura consiste en un camino que se contrae (que sirve para capturar contexto) y luego un camino que se expande (simétrico) que permite una localización precisa. Se muestra como la red completa end-to-end puede entrenarse con pocos ejemplos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG\n",
    "*Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.*\n",
    "\n",
    "En este trabajo se explora el efecto que tiene la profundidad de un modelo de red neuronal convolucional en la precisión de una aplicación de reconocimiento de imágenes de gran escala. Se experimenta con redes de distinta profundidad, **pero solamente utilizando filtros de convolución de 3x3**, llegando hasta una profunidad de 16-19 capas. Se demuestra que estos modelos generalizan bien a otros datasets además del utilizado (ImageNet).\n",
    "\n",
    "**Nota: Más detalles de este paper en la parte 2 del proyecto, donde se utiliza un modelo VGG-16 pre-entrenado para realizar Style Transfer (Transfer Learning).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier Initialization\n",
    "*Glorot, X., & Bengio, Y. (2010, March). Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics (pp. 249-256).*\n",
    "\n",
    "Este paper hace referencia a que antes de 2006 los modelos profundos (multi capa) tenían dificultad para entrenarse correctamente, pues la precisión se lograba al aumentar la profundidad, mencionando que una de las razones era que no se poseían mecanismos de inicialización o entrenamiento adecuados. Uno de los hallazgos principales es que la función de activación clásica hasta ese momento **Sigmoid** no era adecuada para modelos profundos con inicialización aleatoria, por su valor medio que podrían llevar a la saturación temprana de algunas capas. Se presenta un estudio de cómo las activaciones y los gradientes varían de capa en capa y, basados en estas consideraciones, se propone **un nuevo esquema de inicialización de parámetros**, que en la práctica resulta en un esquema de convergencia más veloz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO9000\n",
    "*Redmon, J., & Farhadi, A. (2017). YOLO9000: better, faster, stronger. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7263-7271).*\n",
    "\n",
    "Este paper presenta un modelo de detección de objetos que puede detectar más de 9000 categorías de objetos, basados en una mejora de la metodología YOLO (You Only Look Once). La mayor ventaja es que funciona de forma precisa que otros modelos (Faster R-CNN con ResNet) y funcionando más rápido (en tiempo real). Se muestran resultados sobre los datasets ImageNet y COCO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
